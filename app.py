# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import anderson, shapiro
from statsmodels.stats.diagnostic import lilliefors
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import statsmodels.api as sm
from statsmodels.formula.api import ols
import io
import openai
import os

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Analytics Statistics Assistant",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("ü§ñ Analytics Statistics Assistant")
st.markdown("""
Esta aplicaci√≥n te ayuda a realizar an√°lisis estad√≠sticos descriptivos e inferenciales para an√°lisis de datos general.
Carga tus datos y consulta a OpenAI qu√© an√°lisis realizar, luego ejecuta las funciones disponibles.
""")

# Sidebar para configuraci√≥n
st.sidebar.header("üîß Configuraci√≥n")

# Configuraci√≥n de OpenAI API
st.sidebar.subheader("Configuraci√≥n de OpenAI")
openai_api_key = st.sidebar.text_input("Ingresa tu API Key de OpenAI:", type="password")
openai_client = None

if openai_api_key:
    try:
        openai_client = openai.OpenAI(api_key=openai_api_key)
        st.sidebar.success("‚úÖ OpenAI configurado correctamente")
    except Exception as e:
        st.sidebar.error(f"Error configurando OpenAI: {e}")
else:
    st.sidebar.warning("‚ö†Ô∏è Ingresa tu API Key de OpenAI para usar las recomendaciones")

# Funci√≥n para consultar OpenAI
def consultar_openai(prompt, max_tokens=2000, temperature=0.7, model="gpt-4"):
    """Consulta a OpenAI GPT para obtener recomendaciones y explicaciones"""
    try:
        if not openai_client:
            return "Error: Cliente OpenAI no configurado. Por favor, ingresa tu API Key en la barra lateral."
        
        response = openai_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Eres un experto en estad√≠stica aplicada y an√°lisis de datos. Proporciona explicaciones claras, precisas y pr√°cticas."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error al consultar OpenAI: {str(e)}"

# ASISTENTE TE√ìRICO EN ESTAD√çSTICA (se muestra siempre, sin necesidad de datos)
st.subheader("üìö Asistente Te√≥rico en Estad√≠stica")
st.markdown("""
Consulta conceptos te√≥ricos sobre m√©todos estad√≠sticos, interpretaci√≥n de resultados y mejores pr√°cticas.
*No requiere que tengas datos cargados.*
""")

theory_question = st.text_area(
    "Haz tu pregunta sobre conceptos estad√≠sticos:",
    placeholder="Ej: ¬øCu√°ndo debo usar una prueba T en lugar de ANOVA? ¬øQu√© diferencia hay entre correlaci√≥n y causalidad? ¬øC√≥mo interpreto un p-valor? ¬øQu√© son las pruebas no param√©tricas y cu√°ndo usarlas?",
    height=120,
    key="theory_question_main"
)

if st.button("Consultar teor√≠a estad√≠stica", key="theory_consultation_main") and theory_question:
    if openai_api_key:
        with st.spinner("El experto en estad√≠stica est√° analizando tu consulta..."):
            try:
                # Preparar contexto para asesor√≠a te√≥rica
                theory_context = f"""
                Eres un experto en estad√≠stica aplicada y metodolog√≠a de investigaci√≥n. 
                Responde la siguiente pregunta te√≥rica sobre conceptos estad√≠sticos:
                
                Pregunta del usuario: {theory_question}
                
                Por favor, proporciona una explicaci√≥n clara y completa que incluya:
                
                1. **Definici√≥n conceptual**: Explica el concepto estad√≠stico de manera accesible
                2. **Cu√°ndo aplicarlo**: En qu√© situaciones o tipos de datos se utiliza
                3. **Supuestos requeridos**: Qu√© condiciones deben cumplirse
                4. **Interpretaci√≥n**: C√≥mo interpretar los resultados correctamente
                5. **Limitaciones y consideraciones**: Precauciones y casos donde no aplica
                6. **Ejemplos pr√°cticos**: Ejemplos ilustrativos del concepto
                7. **Relaci√≥n con otros conceptos**: C√≥mo se relaciona con otros m√©todos estad√≠sticos
                
                Si la pregunta involucra comparar m√©todos (ej: T-test vs ANOVA), incluye:
                - Diferencias clave entre los m√©todos
                - Ventajas y desventajas de cada uno
                - Criterios para elegir entre ellos
                - Ejemplos espec√≠ficos de aplicaci√≥n
                
                Mant√©n un tono pedag√≥gico pero preciso, adecuado para profesionales que necesitan aplicar estos conceptos en an√°lisis de datos.
                """
                
                theory_response = consultar_openai(theory_context)
                st.success("üìö Respuesta del Experto en Estad√≠stica:")
                
                # Mejorar la presentaci√≥n de la respuesta
                st.markdown("---")
                st.markdown(theory_response)
                st.markdown("---")
                
            except Exception as e:
                st.error(f"Error en la consulta te√≥rica: {e}")
    else:
        st.error("üîë Necesitas configurar tu API Key de OpenAI en la barra lateral para usar el asistente te√≥rico")

# Informaci√≥n sobre el asistente te√≥rico
with st.expander("üí° ¬øQu√© puedo preguntar al asistente te√≥rico?"):
    st.markdown("""
    **Ejemplos de preguntas que puedes hacer:**
    
    - **Conceptos b√°sicos**: "¬øQu√© es un p-valor y c√≥mo lo interpreto?"
    - **Comparaci√≥n de m√©todos**: "¬øCu√°ndo usar ANOVA en lugar de pruebas T?"
    - **Supuestos**: "¬øQu√© supuestos debe cumplir una regresi√≥n lineal?"
    - **Interpretaci√≥n**: "¬øC√≥mo interpreto un intervalo de confianza del 95%?"
    - **Selecci√≥n de tests**: "¬øCu√°ndo debo usar pruebas param√©tricas vs no param√©tricas?"
    - **Dise√±o de estudios**: "¬øQu√© consideraciones debo tener para un estudio A/B?"
    - **Errores comunes**: "¬øCu√°les son los errores m√°s comunes en la interpretaci√≥n estad√≠stica?"
    - **Tama√±o de muestra**: "¬øC√≥mo determino el tama√±o de muestra adecuado para mi estudio?"
    
    **Este asistente es puramente te√≥rico y no analiza tus datos espec√≠ficos.**
    """)

# L√≠nea separadora
st.markdown("---")

# Carga de datos (esta parte permanece igual)
st.sidebar.subheader("Carga de Datos")
uploaded_file = st.sidebar.file_uploader("Sube tu archivo Excel o CSV", type=['xlsx', 'csv'])

@st.cache_data
def load_data(file):
    if file.name.endswith('.csv'):
        return pd.read_csv(file)
    else:
        return pd.read_excel(file)

# Funciones de muestreo del notebook
def generate_sample(df, sample_size, method="simple", stratify_col=None, random_state=None):
    """
    Genera un muestreo a partir de un DataFrame, permitiendo elegir entre:
    - Muestreo aleatorio simple
    - Muestreo estratificado
    """
    # Verificar si sample_size es un porcentaje o una cantidad fija
    if isinstance(sample_size, float):
        if sample_size <= 0 or sample_size > 1:
            raise ValueError("Si 'sample_size' es un porcentaje, debe estar entre 0 y 1.")
        sample_size = int(len(df) * sample_size)

    if sample_size <= 0 or sample_size > len(df):
        raise ValueError("El tama√±o de la muestra debe ser mayor que 0 y menor o igual al total de datos.")

    # Muestreo Aleatorio Simple
    if method == "simple":
        sample_df = df.sample(n=sample_size, random_state=random_state)

    # Muestreo Estratificado
    elif method == "stratified":
        if stratify_col is None:
            raise ValueError("Se requiere un 'stratify_col' para realizar el muestreo estratificado.")
        if stratify_col not in df.columns:
            raise ValueError(f"La columna '{stratify_col}' no existe en el DataFrame.")

        sample_df = df.groupby(stratify_col, group_keys=False).apply(
            lambda x: x.sample(n=int(sample_size * len(x) / len(df)), random_state=random_state)
        )

    else:
        raise ValueError("El m√©todo de muestreo debe ser 'simple' o 'stratified'.")

    return sample_df.reset_index(drop=True)

def calculate_sample_size(population_size, margin_of_error=0.05, confidence_level=0.95, proportion=0.5):
    """
    Calcula el tama√±o de muestra requerido en funci√≥n del margen de error, nivel de confianza y proporci√≥n esperada.
    """
    # Validaciones
    if not (0 < margin_of_error < 1):
        raise ValueError("El margen de error debe estar entre 0 y 1.")
    if not (0 < confidence_level < 1):
        raise ValueError("El nivel de confianza debe estar entre 0 y 1.")
    if not (0 < proportion < 1):
        raise ValueError("La proporci√≥n debe estar entre 0 y 1.")
    if population_size <= 0:
        raise ValueError("El tama√±o de la poblaci√≥n debe ser mayor que 0.")

    # Obtener el valor Z correspondiente al nivel de confianza
    z_score = stats.norm.ppf(1 - (1 - confidence_level) / 2)

    # Calcular el tama√±o de muestra sin ajuste finito
    sample_size = (z_score**2 * proportion * (1 - proportion)) / (margin_of_error**2)

    # Ajuste por poblaci√≥n finita (si la poblaci√≥n es peque√±a)
    adjusted_sample_size = sample_size / (1 + (sample_size - 1) / population_size)

    # Redondear al entero superior
    final_sample_size = int(np.ceil(adjusted_sample_size))

    return final_sample_size

df = None
if uploaded_file is not None:
    try:
        df = load_data(uploaded_file)
        # Eliminar columna Unnamed: 0 si existe
        if 'Unnamed: 0' in df.columns:
            df = df.drop('Unnamed: 0', axis=1)
        st.sidebar.success(f"‚úÖ Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas")
    except Exception as e:
        st.sidebar.error(f"Error cargando archivo: {e}")

# Mostrar datos si est√°n cargados
if df is not None:
    st.subheader("üìã Vista previa de los datos")
    st.dataframe(df.head())
    
    # Informaci√≥n b√°sica del dataset
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total de registros", df.shape[0])
    with col2:
        st.metric("Total de variables", df.shape[1])
    with col3:
        st.metric("Valores faltantes", df.isnull().sum().sum())
    
    # Selector de variables
    st.subheader("üîç Selecci√≥n de variables")
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    col1, col2 = st.columns(2)
    with col1:
        if numeric_cols:
            selected_numeric = st.multiselect("Variables num√©ricas:", numeric_cols, default=numeric_cols[:2] if len(numeric_cols) >= 2 else numeric_cols)
        else:
            st.warning("No se encontraron variables num√©ricas")
    
    with col2:
        if categorical_cols:
            selected_categorical = st.multiselect("Variables categ√≥ricas:", categorical_cols, default=categorical_cols[0] if categorical_cols else None)
        else:
            st.warning("No se encontraron variables categ√≥ricas")

    # Secci√≥n de consulta a OpenAI PARA DATOS ESPEC√çFICOS (esta va despu√©s de cargar datos)
    st.subheader("ü§ñ Asistente de An√°lisis para tus Datos")
    st.markdown("Consulta recomendaciones espec√≠ficas basadas en los datos que has cargado.")
    
    user_question = st.text_area(
        "Describe tu caso de negocio o pregunta qu√© an√°lisis realizar con tus datos:",
        placeholder="Ej: Quiero analizar si hay diferencias en la satisfacci√≥n laboral entre departamentos, y c√≥mo se relaciona con el rendimiento...",
        height=100,
        key="business_question_main"
    )
    
    if st.button("Obtener recomendaciones de an√°lisis", key="business_recommendations_main") and user_question:
        if openai_api_key:
            with st.spinner("OpenAI est√° analizando tu caso y datos..."):
                try:
                    # Preparar contexto para OpenAI
                    context = f"""
                    Tengo un dataset de an√°lisis de datos con {df.shape[0]} filas y {df.shape[1]} columnas.
                    Variables num√©ricas: {numeric_cols}
                    Variables categ√≥ricas: {categorical_cols}
                    
                    Pregunta del usuario: {user_question}
                    
                    Recomienda qu√© an√°lisis estad√≠sticos espec√≠ficos realizar de esta lista:
                    - Muestreo (tama√±o de muestra, muestreo aleatorio, estratificado)
                    - An√°lisis descriptivo general
                    - Pruebas de normalidad
                    - Correlaciones entre variables
                    - Pruebas t (una muestra, muestras independientes, pareadas)
                    - ANOVA (una v√≠a, dos v√≠as)
                    - Pruebas no param√©tricas (Mann-Whitney, Kruskal-Wallis, Wilcoxon)
                    - Pruebas de chi-cuadrado
                    - An√°lisis de homogeneidad de varianzas
                    
                    Para cada an√°lisis recomendado, indica:
                    1. Qu√© variables usar
                    2. Qu√© pregunta de negocio responde
                    3. Interpretaci√≥n esperada
                    """
                    
                    response = consultar_openai(context)
                    st.success("üéØ Recomendaciones de An√°lisis para tus Datos:")
                    st.markdown("---")
                    st.write(response)
                    st.markdown("---")
                    
                except Exception as e:
                    st.error(f"Error consultando a OpenAI: {e}")
        else:
            st.error("üîë Necesitas configurar tu API Key de OpenAI en la barra lateral")

# Secci√≥n de an√°lisis estad√≠sticos
if df is not None:
    st.header("üìä An√°lisis Estad√≠sticos")
    
    # Crear pesta√±as para diferentes tipos de an√°lisis
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "üéØ Muestreo", 
        "üìà Descriptivos", 
        "üîç Normalidad", 
        "üìâ Correlaciones",
        "‚öñÔ∏è Homogeniedad de Varianzas",
        "‚úÖ Pruebas T",
        "üìä ANOVA",
        "üîÑ No Param√©tricas"
    ])
    
    with tab1:  # Muestreo
        st.subheader("üéØ An√°lisis de Muestreo")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä Generar Muestra")
            st.markdown("Genera una muestra representativa de tus datos para an√°lisis.")
            
            sample_method = st.radio(
                "M√©todo de muestreo:",
                ["simple", "stratified"],
                format_func=lambda x: "Aleatorio Simple" if x == "simple" else "Estratificado"
            )
            
            sample_size_type = st.radio(
                "Tipo de tama√±o de muestra:",
                ["percentage", "absolute"],
                format_func=lambda x: "Porcentaje" if x == "percentage" else "N√∫mero absoluto"
            )
            
            if sample_size_type == "percentage":
                sample_size_input = st.slider(
                    "Porcentaje de muestra:",
                    min_value=1,
                    max_value=50,
                    value=20,
                    help="Porcentaje del total de datos a incluir en la muestra"
                )
                sample_size = sample_size_input / 100.0
            else:
                sample_size_input = st.number_input(
                    "Tama√±o de muestra:",
                    min_value=1,
                    max_value=len(df),
                    value=min(100, len(df)),
                    help="N√∫mero absoluto de registros para la muestra"
                )
                sample_size = sample_size_input
            
            if sample_method == "stratified" and categorical_cols:
                stratify_column = st.selectbox(
                    "Variable para estratificaci√≥n:",
                    categorical_cols,
                    help="La muestra mantendr√° las proporciones de esta variable categ√≥rica"
                )
            else:
                stratify_column = None
            
            if st.button("üé≤ Generar Muestra", key="generate_sample"):
                try:
                    with st.spinner("Generando muestra..."):
                        sample_df = generate_sample(
                            df, 
                            sample_size, 
                            method=sample_method, 
                            stratify_col=stratify_column, 
                            random_state=42
                        )
                    
                    st.success(f"‚úÖ Muestra generada: {len(sample_df)} registros")
                    
                    # Mostrar informaci√≥n de la muestra
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Tama√±o de muestra", len(sample_df))
                    with col2:
                        st.metric("Porcentaje del total", f"{(len(sample_df)/len(df))*100:.1f}%")
                    
                    # Mostrar preview de la muestra
                    st.subheader("Vista previa de la muestra")
                    st.dataframe(sample_df.head())
                    
                    # Mostrar distribuci√≥n si es muestreo estratificado
                    if sample_method == "stratified" and stratify_column:
                        st.subheader("üìã Distribuci√≥n en la muestra")
                        sample_dist = sample_df[stratify_column].value_counts()
                        original_dist = df[stratify_column].value_counts()
                        
                        dist_comparison = pd.DataFrame({
                            'Original': original_dist,
                            'Muestra': sample_dist,
                            '% Original': (original_dist / len(df)) * 100,
                            '% Muestra': (sample_dist / len(sample_df)) * 100
                        })
                        
                        st.dataframe(dist_comparison)
                        
                        # Gr√°fico de comparaci√≥n
                        fig, ax = plt.subplots(1, 2, figsize=(12, 4))
                        
                        # Gr√°fico original
                        original_dist.plot(kind='bar', ax=ax[0], color='skyblue', alpha=0.7)
                        ax[0].set_title('Distribuci√≥n Original')
                        ax[0].set_ylabel('Frecuencia')
                        ax[0].tick_params(axis='x', rotation=45)
                        
                        # Gr√°fico muestra
                        sample_dist.plot(kind='bar', ax=ax[1], color='lightcoral', alpha=0.7)
                        ax[1].set_title('Distribuci√≥n en Muestra')
                        ax[1].set_ylabel('Frecuencia')
                        ax[1].tick_params(axis='x', rotation=45)
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                    
                    # Opci√≥n para descargar la muestra en Excel
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        sample_df.to_excel(writer, index=False, sheet_name='Muestra')
                    
                    st.download_button(
                        label="üì• Descargar muestra como Excel",
                        data=output.getvalue(),
                        file_name="muestra_generada.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                except Exception as e:
                    st.error(f"‚ùå Error generando muestra: {e}")
        
        with col2:
            st.subheader("üßÆ Calcular Tama√±o de Muestra")
            st.markdown("Calcula el tama√±o m√≠nimo de muestra necesario para tu estudio.")
            
            population_size = st.number_input(
                "Tama√±o de la poblaci√≥n:",
                min_value=1,
                value=len(df),
                help="N√∫mero total de elementos en la poblaci√≥n de estudio"
            )
            
            margin_error = st.slider(
                "Margen de error (%):",
                min_value=1,
                max_value=10,
                value=5,
                help="Precisi√≥n deseada en los resultados (¬±%)"
            ) / 100.0
            
            confidence_level = st.slider(
                "Nivel de confianza (%):",
                min_value=80,
                max_value=99,
                value=95,
                help="Probabilidad de que el resultado sea correcto"
            ) / 100.0
            
            proportion = st.slider(
                "Proporci√≥n esperada (%):",
                min_value=1,
                max_value=99,
                value=50,
                help="Proporci√≥n esperada de la caracter√≠stica en la poblaci√≥n (usar 50% si es desconocida)"
            ) / 100.0
            
            if st.button("üìê Calcular Tama√±o de Muestra", key="calculate_sample_size"):
                try:
                    with st.spinner("Calculando tama√±o de muestra..."):
                        sample_size = calculate_sample_size(
                            population_size=population_size,
                            margin_of_error=margin_error,
                            confidence_level=confidence_level,
                            proportion=proportion
                        )
                    
                    st.success(f"üéØ Tama√±o de muestra recomendado: **{sample_size}**")
                    
                    # Informaci√≥n adicional
                    st.info(f"""
                    **Par√°metros utilizados:**
                    - Poblaci√≥n: {population_size:,}
                    - Margen de error: ¬±{margin_error*100:.1f}%
                    - Nivel de confianza: {confidence_level*100:.1f}%
                    - Proporci√≥n esperada: {proportion*100:.1f}%
                    """)
                    
                    # Comparaci√≥n con datos actuales
                    if population_size == len(df):
                        coverage = (sample_size / len(df)) * 100
                        st.metric(
                            "Cobertura de tu dataset",
                            f"{coverage:.1f}%",
                            delta=f"{sample_size - len(df)} registros" if sample_size > len(df) else None,
                            delta_color="inverse" if sample_size > len(df) else "normal"
                        )
                        
                        if sample_size > len(df):
                            st.warning("‚ö†Ô∏è Tu dataset actual es m√°s peque√±o que el tama√±o de muestra recomendado")
                        else:
                            st.success("‚úÖ Tu dataset actual es suficiente para el an√°lisis")
                    
                except Exception as e:
                    st.error(f"‚ùå Error calculando tama√±o de muestra: {e}")
            
            # Informaci√≥n educativa
            with st.expander("üí° ¬øPor qu√© es importante el muestreo?"):
                st.markdown("""
                **El muestreo adecuado es crucial porque:**
                - Reduce costos y tiempo de an√°lisis
                - Permite trabajar con conjuntos de datos manejables
                - Mantiene la representatividad de la poblaci√≥n
                - Facilita la generalizaci√≥n de resultados
                
                **Tipos de muestreo:**
                - **Aleatorio simple:** Cada elemento tiene igual probabilidad de ser seleccionado
                - **Estratificado:** Mantiene las proporciones de subgrupos importantes
                """)
    
    with tab2:  # An√°lisis descriptivos
        st.subheader("An√°lisis Descriptivo")
        
        # Estad√≠sticas descriptivas b√°sicas
        if numeric_cols:
            st.subheader("Estad√≠sticas Descriptivas por Variable Num√©rica")
            selected_var = st.selectbox("Selecciona variable num√©rica:", numeric_cols, key="desc_var")
            if selected_var:
                desc_stats = df[selected_var].describe()
                st.write(desc_stats)
                
                # Histograma y boxplot
                col1, col2 = st.columns(2)
                with col1:
                    fig, ax = plt.subplots()
                    sns.histplot(df[selected_var], kde=True, ax=ax)
                    ax.set_title(f'Distribuci√≥n de {selected_var}')
                    st.pyplot(fig)
                
                with col2:
                    fig, ax = plt.subplots()
                    sns.boxplot(y=df[selected_var], ax=ax)
                    ax.set_title(f'Boxplot de {selected_var}')
                    st.pyplot(fig)
        
        # Reporte descriptivo simple en lugar del profiling
        st.subheader("Reporte Descriptivo Resumido")
        st.markdown("Genera un reporte resumido de an√°lisis exploratorio de datos.")
        
        if st.button("üìä Generar Reporte Descriptivo", key="desc_report_button"):
            with st.spinner("Generando reporte..."):
                try:
                    # An√°lisis descriptivo b√°sico
                    st.subheader("üìã Estad√≠sticas Descriptivas Generales")
                    
                    if numeric_cols:
                        st.write("**Variables Num√©ricas:**")
                        numeric_desc = df[numeric_cols].describe().T
                        numeric_desc['CV'] = (numeric_desc['std'] / numeric_desc['mean']) * 100
                        numeric_desc['missing'] = df[numeric_cols].isnull().sum()
                        st.dataframe(numeric_desc)
                    
                    if categorical_cols:
                        st.write("**Variables Categ√≥ricas:**")
                        for cat_var in categorical_cols:
                            st.write(f"**{cat_var}:**")
                            cat_stats = df[cat_var].value_counts().reset_index()
                            cat_stats.columns = ['Valor', 'Frecuencia']
                            cat_stats['Porcentaje'] = (cat_stats['Frecuencia'] / len(df)) * 100
                            st.dataframe(cat_stats)
                    
                    st.success("‚úÖ Reporte descriptivo generado correctamente.")
                    
                except Exception as e:
                    st.error(f"Error generando reporte: {e}")
    
    with tab3:  # Pruebas de normalidad
        st.subheader("üîç Pruebas de Normalidad")
        st.markdown("Eval√∫a si tus datos siguen una distribuci√≥n normal, requisito para muchas pruebas param√©tricas.")
        
        if numeric_cols:
            selected_normal_var = st.selectbox("Selecciona variable para prueba de normalidad:", numeric_cols, key="normal_var")
            alpha_normal = st.slider("Nivel de significancia (Œ±):", 0.01, 0.10, 0.05, key="normal_alpha")
            
            if st.button("üìä Ejecutar Pruebas de Normalidad"):
                try:
                    data = df[selected_normal_var].dropna()
                    n = len(data)
                    
                    if n < 3:
                        st.error("Se necesitan al menos 3 observaciones para las pruebas de normalidad")
                    else:
                        st.subheader("üìã Resultados de las Pruebas de Normalidad")
                        st.info(f"**Tama√±o de muestra:** {n:,} observaciones")
                        
                        # ==========================================
                        # 1. SHAPIRO-WILK
                        # ==========================================
                        st.markdown("#### 1. Prueba de Shapiro-Wilk")
                        st.caption("Prueba m√°s potente para detectar desviaciones de la normalidad")
                        
                        if n > 5000:
                            st.warning("""
                            ‚ö†Ô∏è **Limitaci√≥n de Shapiro-Wilk con muestras grandes**
                            
                            Con n > 5000, esta prueba se vuelve extremadamente sensible y puede rechazar 
                            normalidad por desviaciones triviales. Los resultados deben interpretarse con 
                            precauci√≥n y complementarse con an√°lisis visual.
                            """)
                            shapiro_stat, shapiro_p = shapiro(data)
                            shapiro_normal = shapiro_p > alpha_normal
                            shapiro_weight = 1  # Peso reducido para muestras grandes
                        else:
                            shapiro_stat, shapiro_p = shapiro(data)
                            shapiro_normal = shapiro_p > alpha_normal
                            shapiro_weight = 3  # Peso alto (m√°s confiable)
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Estad√≠stico W", f"{shapiro_stat:.4f}")
                            st.caption("Rango: [0, 1]. Valores cercanos a 1 indican normalidad")
                        with col2:
                            st.metric("p-valor", f"{shapiro_p:.4f}")
                        
                        # Explicaci√≥n adicional para Shapiro-Wilk
                        with st.expander("‚ÑπÔ∏è Interpretaci√≥n de Shapiro-Wilk"):
                            st.markdown(f"""
                            **C√≥mo funciona Shapiro-Wilk:**
                            
                            Esta prueba compara los datos observados con lo que se esperar√≠a de una distribuci√≥n normal perfecta.
                            
                            **Estad√≠stico W:**
                            - Valor calculado: **{shapiro_stat:.4f}**
                            - Rango posible: 0 a 1
                            - W = 1 ‚Üí distribuci√≥n perfectamente normal
                            - W < 1 ‚Üí desviaci√≥n de la normalidad
                            - En la pr√°ctica: W > 0.95 es considerado bueno
                            
                            **P-valor:**
                            - Valor calculado: **{shapiro_p:.4f}**
                            - Tu nivel Œ±: **{alpha_normal}**
                            - Si p > Œ± ‚Üí NO rechazamos normalidad (datos parecen normales)
                            - Si p ‚â§ Œ± ‚Üí RECHAZAMOS normalidad (datos NO parecen normales)
                            
                            **En este caso:**
                            - p-valor ({shapiro_p:.4f}) {">" if shapiro_normal else "‚â§"} Œ± ({alpha_normal})
                            - **Conclusi√≥n:** {"Los datos SON consistentes con normalidad" if shapiro_normal else "Los datos NO son consistentes con normalidad"}
                            
                            **Ventajas de Shapiro-Wilk:**
                            - ‚úÖ M√°s potente que otras pruebas para n < 2000
                            - ‚úÖ Detecta bien desviaciones en las colas
                            - ‚úÖ F√°cil de interpretar con p-valor exacto
                            
                            **Limitaciones:**
                            - ‚ö†Ô∏è Muy sensible con muestras grandes (n > 5000)
                            - ‚ö†Ô∏è Puede rechazar normalidad por diferencias triviales
                            {"- ‚ö†Ô∏è **TU MUESTRA ES GRANDE (n=" + str(n) + ")** - complementa con gr√°ficos" if n > 5000 else ""}
                            """)
                        
                        if shapiro_normal:
                            st.success("‚úÖ Los datos parecen normales seg√∫n Shapiro-Wilk")
                        else:
                            st.error("‚ùå Los datos NO parecen normales seg√∫n Shapiro-Wilk")
                        
                        # ==========================================
                        # 2. ANDERSON-DARLING
                        # ==========================================
                        st.markdown("#### 2. Prueba de Anderson-Darling")
                        st.caption("Da m√°s peso a las colas de la distribuci√≥n")
                        
                        ad_test = anderson(data, dist='norm')
                        ad_statistic = ad_test.statistic
                        
                        # Mapeo de alpha a √≠ndice de valores cr√≠ticos
                        # ad_test.significance_level = [15.0, 10.0, 5.0, 2.5, 1.0]
                        # ad_test.critical_values tiene los valores cr√≠ticos correspondientes
                        alpha_to_idx = {
                            0.15: 0,
                            0.10: 1,
                            0.05: 2,
                            0.025: 3,
                            0.01: 4
                        }
                        
                        # Encontrar el √≠ndice m√°s cercano al alpha seleccionado
                        closest_alpha = min(alpha_to_idx.keys(), key=lambda x: abs(x - alpha_normal))
                        idx = alpha_to_idx[closest_alpha]
                        critical_value = ad_test.critical_values[idx]
                        
                        # ‚úÖ CORRECCI√ìN: Calcular rango de p-valor correctamente
                        # Si estad√≠stico < valor cr√≠tico ‚Üí NO se rechaza normalidad ‚Üí p > nivel
                        # Si estad√≠stico >= valor cr√≠tico ‚Üí SE rechaza normalidad ‚Üí p < nivel
                        if ad_statistic < ad_test.critical_values[0]:
                            # Estad√≠stico muy peque√±o ‚Üí fuerte evidencia de normalidad
                            p_value_range = f"> {ad_test.significance_level[0]/100:.2f}"
                            p_value_numeric = 0.20  # Para comparaciones num√©ricas
                            p_value_interpretation = f"El p-valor es mayor a {ad_test.significance_level[0]/100:.2f}"
                        elif ad_statistic >= ad_test.critical_values[-1]:
                            # Estad√≠stico muy grande ‚Üí fuerte evidencia contra normalidad
                            p_value_range = f"< {ad_test.significance_level[-1]/100:.2f}"
                            p_value_numeric = 0.005  # Para comparaciones num√©ricas
                            p_value_interpretation = f"El p-valor es menor a {ad_test.significance_level[-1]/100:.2f}"
                        else:
                            # Estad√≠stico est√° entre dos valores cr√≠ticos
                            for i in range(len(ad_test.critical_values) - 1):
                                if ad_test.critical_values[i] <= ad_statistic < ad_test.critical_values[i+1]:
                                    lower_sig = ad_test.significance_level[i+1] / 100
                                    upper_sig = ad_test.significance_level[i] / 100
                                    p_value_range = f"{lower_sig:.3f} < p < {upper_sig:.3f}"
                                    p_value_numeric = (lower_sig + upper_sig) / 2
                                    p_value_interpretation = f"El p-valor est√° entre {lower_sig:.3f} y {upper_sig:.3f}"
                                    break
                        
                        # ‚úÖ CORRECCI√ìN: Decisi√≥n basada en valores cr√≠ticos, no en p-valor aproximado
                        ad_normal = ad_statistic < critical_value
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Estad√≠stico A-D", f"{ad_statistic:.4f}")
                            st.caption(f"Valor cr√≠tico (Œ±={closest_alpha:.3f}): {critical_value:.3f}")
                        with col2:
                            st.metric("p-valor (rango aproximado)", p_value_range)
                            st.caption("‚ö†Ô∏è A-D proporciona rangos, no p-valores exactos")
                        
                        # Explicaci√≥n adicional para Anderson-Darling
                        with st.expander("‚ÑπÔ∏è Interpretaci√≥n de Anderson-Darling"):
                            st.markdown(f"""
                            **C√≥mo funciona Anderson-Darling:**
                            
                            Esta prueba mide qu√© tan bien los datos se ajustan a una distribuci√≥n normal, 
                            dando **m√°s peso a las colas** (valores extremos) que otras pruebas.
                            
                            **Estad√≠stico A-D:**
                            - Valor calculado: **{ad_statistic:.4f}**
                            - Mide la discrepancia entre los datos y la distribuci√≥n normal
                            - Valores peque√±os ‚Üí buena concordancia con normalidad
                            - Valores grandes ‚Üí pobre concordancia con normalidad
                            
                            **Valores Cr√≠ticos (en lugar de p-valor √∫nico):**
                            
                            Anderson-Darling NO proporciona un p-valor exacto como otras pruebas. 
                            En su lugar, compara el estad√≠stico con valores cr√≠ticos precalculados:
                            
                            | Nivel Œ± | Valor Cr√≠tico |
                            |---------|---------------|
                            | 15%     | {ad_test.critical_values[0]:.3f} |
                            | 10%     | {ad_test.critical_values[1]:.3f} |
                            | 5%      | {ad_test.critical_values[2]:.3f} |
                            | 2.5%    | {ad_test.critical_values[3]:.3f} |
                            | 1%      | {ad_test.critical_values[4]:.3f} |
                            
                            **Regla de decisi√≥n:**
                            - Si Estad√≠stico **<** Valor Cr√≠tico ‚Üí NO rechazamos normalidad
                            - Si Estad√≠stico **‚â•** Valor Cr√≠tico ‚Üí RECHAZAMOS normalidad
                            
                            **En este caso (Œ± = {closest_alpha}):**
                            - Estad√≠stico A-D: **{ad_statistic:.4f}**
                            - Valor cr√≠tico: **{critical_value:.3f}**
                            - {ad_statistic:.4f} {"<" if ad_normal else "‚â•"} {critical_value:.3f}
                            - {p_value_interpretation}
                            - **Conclusi√≥n:** {"Los datos SON consistentes con normalidad" if ad_normal else "Los datos NO son consistentes con normalidad"}
                            
                            **Ventajas de Anderson-Darling:**
                            - ‚úÖ M√°s sensible en las colas (detecta outliers)
                            - ‚úÖ Funciona bien con muestras peque√±as y grandes
                            - ‚úÖ No tiene l√≠mite superior de tama√±o de muestra
                            
                            **Limitaciones:**
                            - ‚ö†Ô∏è No proporciona p-valor exacto (solo rangos)
                            - ‚ö†Ô∏è Interpretaci√≥n menos intuitiva que Shapiro-Wilk
                            - ‚ö†Ô∏è Requiere entender valores cr√≠ticos
                            """)
                        
                        if ad_normal:
                            st.success("‚úÖ Los datos parecen normales seg√∫n Anderson-Darling")
                        else:
                            st.error("‚ùå Los datos NO parecen normales seg√∫n Anderson-Darling")
                        
                        # ==========================================
                        # 3. LILLIEFORS
                        # ==========================================
                        st.markdown("#### 3. Prueba de Kolmogorov-Smirnov (Lilliefors)")
                        st.caption("Versi√≥n mejorada de K-S que estima par√°metros de los datos")
                        
                        lilliefors_stat, lilliefors_p = lilliefors(data)
                        lilliefors_normal = lilliefors_p > alpha_normal
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Estad√≠stico D", f"{lilliefors_stat:.4f}")
                            st.caption("Mide la m√°xima distancia entre distribuciones")
                        with col2:
                            st.metric("p-valor", f"{lilliefors_p:.4f}")
                        
                        # Explicaci√≥n adicional para Lilliefors
                        with st.expander("‚ÑπÔ∏è Interpretaci√≥n de Kolmogorov-Smirnov (Lilliefors)"):
                            st.markdown(f"""
                            **C√≥mo funciona Lilliefors (K-S modificado):**
                            
                            Esta prueba compara la distribuci√≥n acumulada emp√≠rica de tus datos con 
                            la distribuci√≥n normal acumulada te√≥rica. Es una **versi√≥n mejorada** de 
                            la cl√°sica prueba Kolmogorov-Smirnov.
                            
                            **Estad√≠stico D (Distancia):**
                            - Valor calculado: **{lilliefors_stat:.4f}**
                            - Mide la **m√°xima diferencia vertical** entre:
                            - La distribuci√≥n acumulada de tus datos (escalera)
                            - La curva normal acumulada te√≥rica (S suave)
                            - D = 0 ‚Üí Ajuste perfecto (imposible en pr√°ctica)
                            - D peque√±o (< 0.05) ‚Üí Buen ajuste
                            - D grande (> 0.15) ‚Üí Mal ajuste
                            
                            **Interpretaci√≥n del estad√≠stico D:**
                            """)
                            
                            # Interpretaci√≥n visual del estad√≠stico D
                            if lilliefors_stat < 0.05:
                                st.success(f"üìä D = {lilliefors_stat:.4f} < 0.05 ‚Üí **Excelente ajuste** a la normalidad")
                            elif lilliefors_stat < 0.10:
                                st.info(f"üìä D = {lilliefors_stat:.4f} ‚àà [0.05, 0.10) ‚Üí **Buen ajuste** a la normalidad")
                            elif lilliefors_stat < 0.15:
                                st.warning(f"üìä D = {lilliefors_stat:.4f} ‚àà [0.10, 0.15) ‚Üí **Ajuste moderado** a la normalidad")
                            else:
                                st.error(f"üìä D = {lilliefors_stat:.4f} ‚â• 0.15 ‚Üí **Mal ajuste** a la normalidad")
                            
                            st.markdown(f"""
                            **P-valor:**
                            - Valor calculado: **{lilliefors_p:.4f}**
                            - Tu nivel Œ±: **{alpha_normal}**
                            - Representa la probabilidad de obtener un D tan grande (o mayor) si los datos fueran realmente normales
                            
                            **Regla de decisi√≥n:**
                            - Si p > Œ± ‚Üí NO rechazamos normalidad (diferencia podr√≠a ser por azar)
                            - Si p ‚â§ Œ± ‚Üí RECHAZAMOS normalidad (diferencia es significativa)
                            
                            **En este caso:**
                            - p-valor ({lilliefors_p:.4f}) {">" if lilliefors_normal else "‚â§"} Œ± ({alpha_normal})
                            - **Conclusi√≥n:** {"Los datos SON consistentes con normalidad" if lilliefors_normal else "Los datos NO son consistentes con normalidad"}
                            
                            **Diferencia con K-S cl√°sico:**
                            
                            | Aspecto | K-S Cl√°sico | Lilliefors |
                            |---------|-------------|------------|
                            | Par√°metros | Deben ser conocidos | Se estiman de los datos |
                            | Uso t√≠pico | Distribuciones espec√≠ficas | Normalidad con par√°metros desconocidos |
                            | Conservadurismo | M√°s liberal | M√°s conservador (correcto) |
                            
                            **Ventajas de Lilliefors:**
                            - ‚úÖ No requiere conocer Œº y œÉ de antemano
                            - ‚úÖ M√°s apropiado que K-S cl√°sico para normalidad
                            - ‚úÖ P-valor exacto y f√°cil de interpretar
                            - ‚úÖ Funciona bien con muestras peque√±as
                            
                            **Limitaciones:**
                            - ‚ö†Ô∏è Menos potente que Shapiro-Wilk
                            - ‚ö†Ô∏è Sensible a desviaciones en el centro m√°s que en las colas
                            - ‚ö†Ô∏è Con n muy peque√±o (< 20) puede tener baja potencia
                            
                            **¬øCu√°ndo usar Lilliefors?**
                            - ‚úì Cuando tienes muestras peque√±as a medianas (20-500)
                            - ‚úì Como complemento a Shapiro-Wilk
                            - ‚úì Cuando quieres una prueba m√°s conservadora
                            - ‚úì Para reportar en art√≠culos (ampliamente reconocida)
                            """)
                        
                        if lilliefors_normal:
                            st.success("‚úÖ Los datos parecen normales seg√∫n Lilliefors")
                        else:
                            st.error("‚ùå Los datos NO parecen normales seg√∫n Lilliefors")
                        
                        # ==========================================
                        # CONCLUSI√ìN FINAL
                        # ==========================================
                        st.markdown("---")
                        st.subheader("üéØ CONCLUSI√ìN INTEGRADA")
                        
                        # Crear tabla resumen con pesos
                        results_data = [
                            {
                                'Prueba': 'Shapiro-Wilk',
                                'Estad√≠stico': f"{shapiro_stat:.4f}",
                                'p-valor': f"{shapiro_p:.4f}" if n <= 5000 else f"{shapiro_p:.4f} ‚ö†Ô∏è",
                                'Resultado': '‚úÖ Normal' if shapiro_normal else '‚ùå No Normal',
                                'Peso': shapiro_weight
                            },
                            {
                                'Prueba': 'Anderson-Darling',
                                'Estad√≠stico': f"{ad_statistic:.4f}",
                                'p-valor': p_value_range,
                                'Resultado': '‚úÖ Normal' if ad_normal else '‚ùå No Normal',
                                'Peso': 2
                            },
                            {
                                'Prueba': 'Lilliefors',
                                'Estad√≠stico': f"{lilliefors_stat:.4f}",
                                'p-valor': f"{lilliefors_p:.4f}",
                                'Resultado': '‚úÖ Normal' if lilliefors_normal else '‚ùå No Normal',
                                'Peso': 2
                            }
                        ]
                        
                        results_df = pd.DataFrame(results_data)
                        st.dataframe(results_df, hide_index=True, use_container_width=True)
                        
                        # Calcular consenso ponderado
                        total_weight = shapiro_weight + 2 + 2
                        passed_weight = (
                            (shapiro_weight if shapiro_normal else 0) +
                            (2 if ad_normal else 0) +
                            (2 if lilliefors_normal else 0)
                        )
                        consensus = passed_weight / total_weight
                        
                        st.metric("Consenso Ponderado", f"{consensus*100:.1f}%", 
                                help="Porcentaje de evidencia (ponderado por confiabilidad) que apoya la normalidad")
                        
                        # Decisi√≥n final con matices
                        if consensus >= 0.7:
                            st.success(f"""
                            ‚úÖ **CONCLUSI√ìN: LOS DATOS PARECEN SEGUIR UNA DISTRIBUCI√ìN NORMAL**
                            
                            **Consenso:** {consensus*100:.0f}% de las pruebas ponderadas
                            
                            **‚úì Puedes usar pruebas param√©tricas:**
                            - Prueba T de Student
                            - ANOVA
                            - Correlaci√≥n de Pearson
                            - Regresi√≥n lineal
                            """)
                        elif consensus >= 0.4:
                            st.warning(f"""
                            ‚ö†Ô∏è **CONCLUSI√ìN: EVIDENCIA MIXTA SOBRE NORMALIDAD**
                            
                            **Consenso:** {consensus*100:.0f}% de las pruebas ponderadas
                            
                            **Recomendaciones:**
                            1. üìä Revisa cuidadosamente los gr√°ficos Q-Q y el histograma
                            2. üîÑ Considera transformaciones de datos:
                            - Logar√≠tmica: para datos con sesgo positivo
                            - Ra√≠z cuadrada: para datos de conteo
                            - Box-Cox: transformaci√≥n √≥ptima autom√°tica
                            3. üìè Si n > 30, las pruebas param√©tricas son robustas (Teorema Central del L√≠mite)
                            4. üõ°Ô∏è Como alternativa segura, usa pruebas no param√©tricas
                            """)
                        else:
                            st.error(f"""
                            ‚ùå **CONCLUSI√ìN: LOS DATOS NO PARECEN SEGUIR UNA DISTRIBUCI√ìN NORMAL**
                            
                            **Consenso:** {consensus*100:.0f}% de las pruebas ponderadas
                            
                            **Opciones recomendadas:**
                            
                            **1. Transformaciones de datos:**
                            - `log(x)` - para datos con sesgo positivo
                            - `sqrt(x)` - para datos de conteo
                            - `1/x` - para tiempos o tasas
                            - Box-Cox o Yeo-Johnson - transformaci√≥n √≥ptima
                            
                            **2. Usar pruebas no param√©tricas:**
                            - Mann-Whitney U (en lugar de prueba T independiente)
                            - Wilcoxon (en lugar de prueba T pareada)
                            - Kruskal-Wallis (en lugar de ANOVA)
                            - Spearman (en lugar de Pearson)
                            
                            **3. Modelos robustos:** T√©cnicas que no asumen normalidad
                            """)
                        
                        # Consideraciones sobre tama√±o de muestra
                        if n < 30:
                            sample_size_msg = f"**n = {n} (< 30):** La normalidad es CR√çTICA. Considera pruebas no param√©tricas si hay dudas."
                            sample_size_color = "üî¥"
                        elif n < 100:
                            sample_size_msg = f"**n = {n} (30-100):** La normalidad es importante, pero las pruebas param√©tricas tienen cierta robustez."
                            sample_size_color = "üü°"
                        elif n < 1000:
                            sample_size_msg = f"**n = {n} (100-1000):** Con este tama√±o, las pruebas param√©tricas son bastante robustas a desviaciones leves de normalidad."
                            sample_size_color = "üü¢"
                        else:
                            sample_size_msg = f"**n = {n} (> 1000):** Las pruebas de normalidad pueden ser hipersensibles. Prioriza la validaci√≥n visual y el sentido del negocio."
                            sample_size_color = "üîµ"
                        
                        st.info(f"""
                        {sample_size_color} **Consideraci√≥n sobre tama√±o de muestra:**
                        
                        {sample_size_msg}
                        
                        **Regla general (Teorema Central del L√≠mite):**
                        - Con muestras grandes (n ‚â• 30), la distribuci√≥n de medias tiende a ser normal
                        - Esto hace que las pruebas param√©tricas sean robustas incluso con datos no normales
                        - EXCEPCI√ìN: Datos con outliers extremos o distribuciones muy asim√©tricas
                        """)
                        
                        # ==========================================
                        # VISUALIZACIONES
                        # ==========================================
                        st.markdown("---")
                        st.subheader("üìä Diagn√≥stico Visual")
                        st.caption("Las visualizaciones son tan importantes como las pruebas estad√≠sticas")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            
                            # Histograma con KDE
                            sns.histplot(data, kde=True, ax=ax, stat='density', alpha=0.7, color='skyblue')
                            
                            # Superponer curva normal te√≥rica
                            mu, sigma = data.mean(), data.std()
                            x = np.linspace(data.min(), data.max(), 100)
                            ax.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, 
                                label=f'Normal te√≥rica\n(Œº={mu:.2f}, œÉ={sigma:.2f})')
                            
                            ax.set_title(f'Distribuci√≥n de {selected_normal_var}', fontsize=12, fontweight='bold')
                            ax.set_xlabel(selected_normal_var, fontsize=10)
                            ax.set_ylabel('Densidad', fontsize=10)
                            ax.legend(loc='best')
                            ax.grid(True, alpha=0.3)
                            
                            st.pyplot(fig)
                            plt.close()
                            
                            st.caption("üìå Los datos deber√≠an seguir aproximadamente la curva roja si son normales")
                        
                        with col2:
                            fig, ax = plt.subplots(figsize=(8, 6))
                            
                            # Q-Q plot
                            stats.probplot(data, dist="norm", plot=ax)
                            ax.set_title(f'Q-Q Plot de {selected_normal_var}', fontsize=12, fontweight='bold')
                            ax.grid(True, alpha=0.3)
                            
                            # A√±adir caja de interpretaci√≥n
                            textstr = 'Interpretaci√≥n:\n‚Ä¢ Puntos en l√≠nea roja\n  ‚Üí Normal\n‚Ä¢ Curva en extremos\n  ‚Üí Colas pesadas\n‚Ä¢ S invertida\n  ‚Üí Asimetr√≠a'
                            props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
                            ax.text(0.05, 0.95, textstr, transform=ax.transAxes,
                                fontsize=9, verticalalignment='top', bbox=props)
                            
                            st.pyplot(fig)
                            plt.close()
                            
                            st.caption("üìå Los puntos deber√≠an caer sobre la l√≠nea roja si los datos son normales")
                        
                        # Boxplot adicional para detectar outliers
                        st.markdown("#### Detecci√≥n de Valores At√≠picos")
                        fig, ax = plt.subplots(figsize=(10, 4))
                        sns.boxplot(x=data, ax=ax, color='lightcoral')
                        ax.set_xlabel(selected_normal_var, fontsize=10)
                        ax.set_title(f'Boxplot de {selected_normal_var} (Detecci√≥n de Outliers)', 
                                    fontsize=12, fontweight='bold')
                        ax.grid(True, alpha=0.3, axis='x')
                        
                        st.pyplot(fig)
                        plt.close()
                        
                        # Calcular outliers
                        Q1 = data.quantile(0.25)
                        Q3 = data.quantile(0.75)
                        IQR = Q3 - Q1
                        outliers = data[(data < Q1 - 1.5*IQR) | (data > Q3 + 1.5*IQR)]
                        
                        if len(outliers) > 0:
                            st.warning(f"‚ö†Ô∏è Se detectaron {len(outliers)} valores at√≠picos ({len(outliers)/len(data)*100:.1f}% de los datos)")
                            st.caption("Los outliers pueden afectar las pruebas de normalidad. Considera investigar estos valores.")
                        else:
                            st.success("‚úÖ No se detectaron valores at√≠picos significativos")
                        
                except Exception as e:
                    st.error(f"Error en pruebas de normalidad: {e}")
                    import traceback
                    st.code(traceback.format_exc())
        else:
            st.warning("No hay variables num√©ricas para analizar")

    with tab4:  # Correlaciones
        st.subheader("üìâ An√°lisis de Correlaci√≥n")
        st.markdown("Analiza la relaci√≥n entre dos variables num√©ricas.")
        
        if len(numeric_cols) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                var1 = st.selectbox("Variable 1:", numeric_cols, key="corr_var1")
            with col2:
                var2 = st.selectbox("Variable 2:", numeric_cols, key="corr_var2")
            
            alpha_corr = st.slider("Nivel de significancia (Œ±):", 0.01, 0.10, 0.05, key="corr_alpha")
            
            if st.button("üîç Analizar Correlaci√≥n"):
                try:
                    # Filtrar valores nulos
                    clean_data = df[[var1, var2]].dropna()
                    
                    if len(clean_data) < 3:
                        st.error("Se necesitan al menos 3 observaciones v√°lidas para calcular la correlaci√≥n")
                    else:
                        # Pruebas de normalidad
                        shapiro_stat1, shapiro_p1 = shapiro(clean_data[var1])
                        shapiro_stat2, shapiro_p2 = shapiro(clean_data[var2])
                        
                        normal1 = shapiro_p1 > alpha_corr
                        normal2 = shapiro_p2 > alpha_corr
                        
                        # Seleccionar m√©todo de correlaci√≥n
                        if normal1 and normal2:
                            corr, p_value = stats.pearsonr(clean_data[var1], clean_data[var2])
                            method = "Pearson"
                            method_explanation = "**Correlaci√≥n de Pearson:** Mide la relaci√≥n lineal entre variables normales"
                        else:
                            corr, p_value = stats.spearmanr(clean_data[var1], clean_data[var2])
                            method = "Spearman"
                            method_explanation = "**Correlaci√≥n de Spearman:** Mide la relaci√≥n monot√≥nica (no necesariamente lineal)"
                        
                        # Resultados
                        st.subheader("üìä Resultados del An√°lisis de Correlaci√≥n")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("M√©todo utilizado", method)
                        with col2:
                            st.metric("Coeficiente de correlaci√≥n", f"{corr:.4f}")
                        with col3:
                            st.metric("p-valor", f"{p_value:.4f}")
                        
                        st.info(method_explanation)
                        
                        # Interpretaci√≥n de la fuerza
                        if abs(corr) < 0.1:
                            strength = "muy d√©bil o inexistente"
                        elif abs(corr) < 0.3:
                            strength = "d√©bil"
                        elif abs(corr) < 0.5:
                            strength = "moderada"
                        elif abs(corr) < 0.7:
                            strength = "fuerte"
                        else:
                            strength = "muy fuerte"
                        
                        # Direcci√≥n
                        direction = "positiva" if corr > 0 else "negativa"
                        
                        st.write(f"**Interpretaci√≥n:** La correlaci√≥n entre **{var1}** y **{var2}** es {strength} y {direction}.")
                        
                        # Significancia estad√≠stica
                        if p_value < alpha_corr:
                            st.success("‚úÖ **La correlaci√≥n es estad√≠sticamente significativa**")
                        else:
                            st.warning("‚ö†Ô∏è **La correlaci√≥n no es estad√≠sticamente significativa**")
                        
                        # Gr√°fico de dispersi√≥n
                        st.subheader("üìà Gr√°fico de Dispersi√≥n")
                        fig, ax = plt.subplots(figsize=(8, 6))
                        sns.scatterplot(data=clean_data, x=var1, y=var2, alpha=0.6, ax=ax)
                        
                        # A√±adir l√≠nea de tendencia
                        z = np.polyfit(clean_data[var1], clean_data[var2], 1)
                        p = np.poly1d(z)
                        ax.plot(clean_data[var1], p(clean_data[var1]), "r--", alpha=0.8)
                        
                        ax.set_title(f'Correlaci√≥n {method}: {var1} vs {var2}\n(r = {corr:.3f}, p = {p_value:.4f})')
                        ax.set_xlabel(var1)
                        ax.set_ylabel(var2)
                        ax.grid(True, alpha=0.3)
                        
                        st.pyplot(fig)
                    
                except Exception as e:
                    st.error(f"Error en an√°lisis de correlaci√≥n: {e}")
        else:
            st.warning("Se necesitan al menos 2 variables num√©ricas para analizar correlaciones")

    # Las dem√°s pesta√±as (tab5 a tab8) se mantienen exactamente iguales...

# Mensaje final si no hay datos cargados
else:
    st.info("üëÜ Por favor, carga un archivo de datos en la barra lateral para comenzar el an√°lisis.")

# Footer
st.markdown("---")
st.markdown(
    "**Analytics Statistics Assistant** - Herramienta para an√°lisis estad√≠sticos generales"
)